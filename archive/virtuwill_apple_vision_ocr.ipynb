{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3469aca-c954-41e2-b3b2-5c8ee5ca4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "VirtuWill - Apple Vision OCR (macOS)\n",
    "\n",
    "Recursively OCRs images in a folder using Apple's Vision framework and writes:\n",
    "1) A .txt file per image (mirrors input folder structure)\n",
    "2) A JSONL manifest with metadata for later fine-tuning\n",
    "\n",
    "Requirements (in your conda env):\n",
    "  python -m pip install pyobjc\n",
    "\n",
    "Recommended:\n",
    "  conda install -y jupyterlab\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699f39ec-394d-4ed2-98e3-ce0c6c866785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… VirtuWill environment verified\n",
      "Python: /opt/anaconda3/envs/virtuwill/bin/python\n",
      "ðŸ“ Python executable:\n",
      "/opt/anaconda3/envs/virtuwill/bin/python\n",
      "\n",
      "ðŸ Python version:\n",
      "3.12.12 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 20:07:49) [Clang 20.1.8 ]\n",
      "\n",
      "ðŸ“¦ Conda environment:\n",
      "virtuwill\n",
      "\n",
      "Current working directory:\n",
      "  /Users/wyoste/Documents/virtuwill\n"
     ]
    }
   ],
   "source": [
    "# === VirtuWill Environment Guard ===\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "EXPECTED_ENV_NAME = \"virtuwill\"\n",
    "\n",
    "def fail(msg):\n",
    "    raise RuntimeError(f\"âŒ ENVIRONMENT ERROR: {msg}\")\n",
    "\n",
    "# 1. Check sys.executable path\n",
    "exe = sys.executable\n",
    "if EXPECTED_ENV_NAME not in exe:\n",
    "    fail(\n",
    "        f\"Notebook is NOT running in '{EXPECTED_ENV_NAME}'.\\n\"\n",
    "        f\"Current Python: {exe}\\n\\n\"\n",
    "        \"Fix:\\n\"\n",
    "        \"  1) Kernel â†’ Change Kernel â†’ Python (virtuwill)\\n\"\n",
    "        \"  2) Restart kernel\\n\"\n",
    "    )\n",
    "\n",
    "# 2. Check conda environment variable (extra safety)\n",
    "conda_env = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "if conda_env != EXPECTED_ENV_NAME:\n",
    "    fail(\n",
    "        f\"CONDA_DEFAULT_ENV='{conda_env}' (expected '{EXPECTED_ENV_NAME}').\\n\"\n",
    "        \"This usually means Jupyter was launched from the wrong environment.\"\n",
    "    )\n",
    "\n",
    "print(f\"âœ… VirtuWill environment verified\\nPython: {exe}\")\n",
    "\n",
    "print(\"ðŸ“ Python executable:\")\n",
    "print(sys.executable)\n",
    "\n",
    "print(\"\\nðŸ Python version:\")\n",
    "print(sys.version)\n",
    "\n",
    "print(\"\\nðŸ“¦ Conda environment:\")\n",
    "print(os.environ.get(\"CONDA_DEFAULT_ENV\"))\n",
    "\n",
    "print(\"\\nCurrent working directory:\")\n",
    "cwd = Path.cwd()\n",
    "print(\" \", cwd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c018df4-c6b1-49cb-89dc-454c0ebf9384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:    /Users/wyoste/Pictures/Journals POC\n",
      "Output:   /Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT\n",
      "Manifest: /Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT/manifest.jsonl\n",
      "Images:   12\n",
      "Lang:     en-US\n",
      "Level:    ACCURATE\n",
      "------------------------------------------------------------\n",
      "[1/12] OK  (235 ms, 9 lines): FF08A95B-48AE-427E-93B8-298E92C1C6A0_4_5005_c.jpeg\n",
      "[2/12] OK  (45 ms, 27 lines): FE8F1C83-57B2-41A9-B235-97BD5FAC8340_1_102_o.jpeg\n",
      "[3/12] OK  (87 ms, 30 lines): FDCD7133-50D4-4577-8AF1-709BD7691351_1_102_o.jpeg\n",
      "[4/12] OK  (22 ms, 8 lines): FF39CC49-083F-463F-B883-C65921E11C9C_1_102_o.jpeg\n",
      "[5/12] OK  (13 ms, 6 lines): FD1B2179-4444-460B-A56E-030404180C85_4_5005_c.jpeg\n",
      "[6/12] OK  (75 ms, 38 lines): FD487870-9160-49AA-9212-0BC01C4ED8BB_1_102_o.jpeg\n",
      "[7/12] OK  (91 ms, 31 lines): FEAA6AB4-2B21-461B-AC12-917A85BEB1D1_1_102_o.jpeg\n",
      "[8/12] OK  (64 ms, 13 lines): FD7461A8-9F65-406A-A4E1-188B964847C2_1_102_o.jpeg\n",
      "[9/12] OK  (88 ms, 25 lines): FEC331F3-B258-4BC4-B41A-FBB6998A0DD0_1_102_o.jpeg\n",
      "[10/12] OK  (78 ms, 22 lines): FDCE4F2D-5A79-493C-A4C7-F371199A6CC9_1_102_o.jpeg\n",
      "[11/12] OK  (70 ms, 24 lines): FF9509E2-92DE-4008-B5EE-1E47A4284E33_1_102_o.jpeg\n",
      "[12/12] OK  (20 ms, 1 lines): FE0E47A5-9C93-415A-82A4-F09BE1C484F2_1_102_o.jpeg\n",
      "------------------------------------------------------------\n",
      "Done. Failures: 0. Total time: 0s\n",
      "OCR text root: /Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT\n",
      "Manifest:      /Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT/manifest.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Optional, Tuple\n",
    "\n",
    "import objc\n",
    "from Foundation import NSURL, NSAutoreleasePool, NSError\n",
    "from Vision import VNImageRequestHandler, VNRecognizeTextRequest\n",
    "from Quartz import CGImageSourceCreateWithURL, CGImageSourceCreateImageAtIndex\n",
    "\n",
    "\n",
    "SUPPORTED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".heic\", \".webp\"}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OcrResult:\n",
    "    source_image: str\n",
    "    output_txt: str\n",
    "    language: str\n",
    "    recognition_level: str\n",
    "    text: str\n",
    "    num_lines: int\n",
    "    elapsed_ms: int\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "def load_cgimage(image_path: Path):\n",
    "    \"\"\"\n",
    "    Load an image into a CGImage using Quartz/ImageIO.\n",
    "    Avoids PIL and generally works well for JPEG/PNG/HEIC on macOS.\n",
    "    \"\"\"\n",
    "    url = NSURL.fileURLWithPath_(str(image_path))\n",
    "    src = CGImageSourceCreateWithURL(url, None)\n",
    "    if src is None:\n",
    "        raise RuntimeError(f\"Could not create image source for: {image_path}\")\n",
    "    cgimg = CGImageSourceCreateImageAtIndex(src, 0, None)\n",
    "    if cgimg is None:\n",
    "        raise RuntimeError(f\"Could not create CGImage for: {image_path}\")\n",
    "    return cgimg\n",
    "\n",
    "\n",
    "def ocr_apple_vision(\n",
    "    image_path: Path,\n",
    "    language: str = \"en-US\",\n",
    "    accurate: bool = True,\n",
    ") -> Tuple[str, int]:\n",
    "    \"\"\"\n",
    "    OCR an image with Apple Vision.\n",
    "    Returns (text, num_lines).\n",
    "    \"\"\"\n",
    "    cgimg = load_cgimage(image_path)\n",
    "\n",
    "    out = {\"text\": \"\"}\n",
    "\n",
    "    def completion_handler(request, error):\n",
    "        if error is not None:\n",
    "            # error is an NSError (ObjC)\n",
    "            raise RuntimeError(f\"Vision error: {error}\")\n",
    "\n",
    "        observations = request.results() or []\n",
    "        lines = []\n",
    "        for obs in observations:\n",
    "            candidates = obs.topCandidates_(1)\n",
    "            if candidates and len(candidates) > 0:\n",
    "                lines.append(candidates[0].string())\n",
    "        out[\"text\"] = \"\\n\".join(lines)\n",
    "\n",
    "    req = VNRecognizeTextRequest.alloc().initWithCompletionHandler_(completion_handler)\n",
    "\n",
    "    # VNRequestTextRecognitionLevelAccurate = 1, Fast = 0\n",
    "    req.setRecognitionLevel_(1 if accurate else 0)\n",
    "    req.setUsesLanguageCorrection_(True)\n",
    "    req.setRecognitionLanguages_([language])\n",
    "\n",
    "    handler = VNImageRequestHandler.alloc().initWithCGImage_options_(cgimg, None)\n",
    "\n",
    "    ok = handler.performRequests_error_([req], objc.nil)\n",
    "    if not ok:\n",
    "        raise RuntimeError(\"Failed to perform Vision request (performRequests_error_ returned false)\")\n",
    "\n",
    "    text = out[\"text\"]\n",
    "    num_lines = 0 if not text.strip() else text.count(\"\\n\") + 1\n",
    "    return text, num_lines\n",
    "\n",
    "\n",
    "def iter_images(root: Path) -> Iterable[Path]:\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file() and p.suffix.lower() in SUPPORTED_EXTS:\n",
    "            yield p\n",
    "\n",
    "\n",
    "def relative_output_txt(input_root: Path, output_root: Path, image_path: Path) -> Path:\n",
    "    rel = image_path.relative_to(input_root)\n",
    "    # mirror structure, but replace extension with .txt\n",
    "    return (output_root / rel).with_suffix(\".txt\")\n",
    "\n",
    "\n",
    "def ensure_parent(path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_text(path: Path, text: str) -> None:\n",
    "    ensure_parent(path)\n",
    "    path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def append_jsonl(path: Path, record: dict) -> None:\n",
    "    ensure_parent(path)\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"VirtuWill: OCR journal images locally using Apple Vision (macOS).\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input\",\n",
    "        default=\"/Users/wyoste/Pictures/Journals POC\",\n",
    "        help=\"Root folder containing images (default: /Users/wyoste/Pictures/Journals POC)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        default=\"/Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT\",\n",
    "        help=\"Output root folder for OCR .txt files\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--manifest\",\n",
    "        default=\"/Users/wyoste/Pictures/Journals POC/VirtuWill_OCR_TXT/manifest.jsonl\",\n",
    "        help=\"JSONL manifest path for results/metadata\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--language\",\n",
    "        default=\"en-US\",\n",
    "        help=\"Vision OCR language code (default: en-US)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--fast\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Use faster, less accurate recognition (default is Accurate)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--overwrite\",\n",
    "        action=\"store_true\",\n",
    "        help=\"Overwrite existing .txt outputs (default: skip if exists)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--limit\",\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help=\"Process only first N images (0 = no limit)\",\n",
    "    )\n",
    "    # Use parse_known_args to tolerate Jupyter/ipykernel injected flags (e.g. -f kernel.json)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    input_root = Path(args.input).expanduser()\n",
    "    output_root = Path(args.output).expanduser()\n",
    "    manifest_path = Path(args.manifest).expanduser()\n",
    "\n",
    "    if not input_root.exists():\n",
    "        print(f\"ERROR: Input path does not exist: {input_root}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    images = list(iter_images(input_root))\n",
    "    if args.limit and args.limit > 0:\n",
    "        images = images[: args.limit]\n",
    "\n",
    "    if not images:\n",
    "        print(f\"No supported images found under: {input_root}\")\n",
    "        return\n",
    "\n",
    "    recognition_level = \"FAST\" if args.fast else \"ACCURATE\"\n",
    "    print(f\"Input:    {input_root}\")\n",
    "    print(f\"Output:   {output_root}\")\n",
    "    print(f\"Manifest: {manifest_path}\")\n",
    "    print(f\"Images:   {len(images)}\")\n",
    "    print(f\"Lang:     {args.language}\")\n",
    "    print(f\"Level:    {recognition_level}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    failures = 0\n",
    "    started = time.time()\n",
    "\n",
    "    # Helps avoid ObjC memory growth during long runs\n",
    "    pool = NSAutoreleasePool.alloc().init()\n",
    "    try:\n",
    "        for i, img_path in enumerate(images, start=1):\n",
    "            rel = img_path.relative_to(input_root)\n",
    "            out_txt = relative_output_txt(input_root, output_root, img_path)\n",
    "\n",
    "            if out_txt.exists() and not args.overwrite:\n",
    "                print(f\"[{i}/{len(images)}] SKIP (exists): {rel}\")\n",
    "                # Still log a manifest record as skipped (optional)\n",
    "                append_jsonl(manifest_path, {\n",
    "                    \"source_image\": str(img_path),\n",
    "                    \"output_txt\": str(out_txt),\n",
    "                    \"status\": \"skipped_exists\",\n",
    "                    \"language\": args.language,\n",
    "                    \"recognition_level\": recognition_level,\n",
    "                    \"timestamp\": int(time.time()),\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                text, num_lines = ocr_apple_vision(\n",
    "                    img_path,\n",
    "                    language=args.language,\n",
    "                    accurate=(not args.fast),\n",
    "                )\n",
    "                elapsed_ms = int((time.time() - t0) * 1000)\n",
    "\n",
    "                write_text(out_txt, text)\n",
    "\n",
    "                append_jsonl(manifest_path, {\n",
    "                    \"source_image\": str(img_path),\n",
    "                    \"output_txt\": str(out_txt),\n",
    "                    \"status\": \"ok\",\n",
    "                    \"language\": args.language,\n",
    "                    \"recognition_level\": recognition_level,\n",
    "                    \"num_lines\": num_lines,\n",
    "                    \"elapsed_ms\": elapsed_ms,\n",
    "                    \"timestamp\": int(time.time()),\n",
    "                })\n",
    "\n",
    "                print(f\"[{i}/{len(images)}] OK  ({elapsed_ms} ms, {num_lines} lines): {rel}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                failures += 1\n",
    "                elapsed_ms = int((time.time() - t0) * 1000)\n",
    "\n",
    "                append_jsonl(manifest_path, {\n",
    "                    \"source_image\": str(img_path),\n",
    "                    \"output_txt\": str(out_txt),\n",
    "                    \"status\": \"error\",\n",
    "                    \"language\": args.language,\n",
    "                    \"recognition_level\": recognition_level,\n",
    "                    \"elapsed_ms\": elapsed_ms,\n",
    "                    \"error\": str(e),\n",
    "                    \"timestamp\": int(time.time()),\n",
    "                })\n",
    "\n",
    "                print(f\"[{i}/{len(images)}] FAIL ({elapsed_ms} ms): {rel} :: {e}\", file=sys.stderr)\n",
    "\n",
    "    finally:\n",
    "        del pool\n",
    "\n",
    "    total_s = int(time.time() - started)\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Done. Failures: {failures}. Total time: {total_s}s\")\n",
    "    print(f\"OCR text root: {output_root}\")\n",
    "    print(f\"Manifest:      {manifest_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d7704-1108-4989-b018-036be9adb60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (virtuwill)",
   "language": "python",
   "name": "virtuwill"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
